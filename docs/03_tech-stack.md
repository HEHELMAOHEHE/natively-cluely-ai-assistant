## 3. Технологический стек

Natively построен на современных и надежных технологиях, обеспечивающих высокую производительность, кроссплатформенность и безопасность. Проект использует комбинацию веб-технологий для интерфейса и нативных компонентов для системной интеграции.

### Основные технологии

#### Фронтенд
- **React** — библиотека для создания пользовательских интерфейсов
- **Vite** — современный сборщик с мгновенной загрузкой при разработке
- **TypeScript** — строгая типизация для повышения надежности кода
- **TailwindCSS** — utility-first фреймворк для стилизации
- **Electron** — платформа для создания десктопных приложений на базе Chromium и Node.js

#### Бэкенд и основной процесс
- **Node.js (v20+)** — среда выполнения JavaScript
- **Rust** — используется для нативного захвата аудио напрямую из системы
- **Electron** — обеспечивает доступ к системным API операционной системы
- **SQLite** — локальная реляционная база данных для хранения транскрипций, метаданных и векторных эмбеддингов
- **IPC (Inter-Process Communication)** — механизм взаимодействия между основным процессом Electron и процессами рендеринга

#### Система искусственного интеллекта
- **Google Cloud Speech-to-Text** — преобразование речи в текст через Google STT
- **Groq** — ультрабыстрое ИИ-ускорение с моделями Llama 3
- **OpenAI Whisper** — расшифровка речи от OpenAI
- **Deepgram** — облачная система распознавания речи
- **ElevenLabs** — продвинутое распознавание речи
- **Azure Speech Services** — сервисы распознавания речи от Microsoft
- **IBM Watson** — система распознавания речи от IBM

#### Модели ИИ
- **Gemini 3 Pro/Flash** — рекомендуемый вариант с огромным контекстным окном (2M токенов) и низкой стоимостью
- **OpenAI GPT-5.2** — высокие способности к рассуждению
- **Anthropic Claude 4.5** — отличное понимание кода и сложных задач
- **Groq/Llama 3** — невероятная скорость ответов (почти мгновенные)
- **Ollama** — поддержка полностью локальных моделей (Llama 3, Mistral, Gemma, CodeLlama)

#### Дополнительные технологии
- **Sharp** — оптимизированная библиотека для обработки изображений, обеспечивающая быстрый анализ скриншотов
- **electron-updater** — автоматическое обновление приложения
- **AutoUpdater** — менеджер обновлений для Electron-приложений
- **ReleaseNotesManager** — управление информацией о релизах

### Архитектурные решения

#### Клиент-серверная модель внутри Electron
Приложение использует классическую архитектуру Electron:
- **Основной процесс**: управляет жизненным циклом приложения, окнами, системными событиями, аудио-захватом и базой данных
- **Процесс рендеринга**: отвечает за отображение интерфейса, взаимодействие с пользователем и визуализацию результатов ИИ

Между этими процессами осуществляется взаимодействие через IPC (Inter-Process Communication), что обеспечивает безопасность и изоляцию.

#### Локальное хранилище и RAG
- **SQLite** используется как основное хранилище данных
- Реализована система **Local RAG (Retrieval Augmented Generation)** с локальной векторной базой данных
- Все векторные эмбеддинги создаются и хранятся исключительно на устройстве пользователя
- Поддерживается семантический поиск по истории встреч ("Что Джон говорил об API на прошлой неделе?")

#### Аудио-система
- **System Audio Capture** — захватывает аудио напрямую из операционной системы (Zoom, Teams, Meet)
- **Microphone Capture** — отдельный канал для микрофона пользователя
- Поддержка двойного аудио-канала: один для собеседников, другой для команд пользователя
- Нативная реализация на Rust для эффективного захвата системного звука без задержек

#### Управление зависимостями
Проект использует npm/yarn для управления пакетами:
```bash
npm install
```

Ключевые зависимости включают:
- `electron` — основа приложения
- `react`, `vite` — интерфейс
- `sqlite3` — работа с базой данных
- `sharp` — обработка изображений
- `axios/fetch` — HTTP-запросы к API
- `socket.io/electron-ipc` — внутренняя коммуникация

### Интеграции с внешними сервисами

#### BYOK (Bring Your Own Keys)
Пользователь предоставляет свои собственные ключи для облачных сервисов:
- `GEMINI_API_KEY` — для доступа к Gemini
- `GROQ_API_KEY` — для использования Groq
- `OPENAI_API_KEY` — для работы с OpenAI
- `CLAUDE_API_KEY` — для доступа к Anthropic Claude
- `GOOGLE_APPLICATION_CREDENTIALS` — путь к JSON-файлу сервисного аккаунта Google для STT

#### Конфигурация через .env
```env
# Cloud AI
GEMINI_API_KEY=your_key
GROQ_API_KEY=your_key
OPENAI_API_KEY=your_key
CLAUDE_API_KEY=your_key
GOOGLE_APPLICATION_CREDENTIALS=/absolute/path/to/service-account.json

# Speech Providers
DEEPGRAM_API_KEY=your_key
ELEVENLABS_API_KEY=your_key
AZURE_SPEECH_KEY=your_key
AZURE_SPEECH_REGION=eastus

# Local AI (Ollama)
USE_OLLAMA=true
OLLAMA_MODEL=llama3.2
OLLAMA_URL=http://localhost:11434

# Default Model Configuration
DEFAULT_MODEL=gemini-3-flash-preview
```

### Системные требования

#### Минимальные требования:
- **Операционная система**: macOS, Windows или Linux
- **RAM**: 4GB (минимально), 8GB+ рекомендуется
- **Дисковое пространство**: ~500MB для установки + место для хранения записей
- **Node.js**: v20 или выше
- **Git**: для клонирования репозитория
- **Rust**: требуется для компиляции нативных аудио-компонентов

#### Рекомендуемые конфигурации:
- Для облачных моделей: 8GB RAM, стабильное интернет-соединение
- Для локальных моделей (Ollama): 16GB+ RAM, мощный CPU/GPU

Этот технологический стек позволяет Natively быть одновременно мощным, гибким и приватным решением, сочетающим лучшие практики веб-разработки с глубокой интеграцией в операционную систему.

